---
title: 'Class 9: Machine Learning'
author: "Nuo Tian"
date: "2/5/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## K-means clustering

Let's try the `kmeans()` function in R to cluster some made-up example data
```{r}
tmp <- c(rnorm(30,-3), rnorm(30,3))
x <- cbind(x=tmp, y=rev(tmp))

plot(x)
```

```{r}
km <- kmeans(x, centers=2, nstart=20)
print(km)
```

What is in the output object `km` Use the "attributes()" function
```{r}
attributes(km)
```

How many points are in each cluster?
```{r}
km$size
```

What 'component' of your result object details
  -cluster size?
  -cluster assignment/membership?
  -cluster center?
  
```{r}
km$centers
km$cluster
```

let's check how many 1s and 2 are in this vector with the `table()` function
```{r}
table(km$cluster)
```

plot x colored by the kmeans cluster assignment and add cluster centers as blue points
```{r}
plot(x, col = km$cluster)
points(km$centers, col="blue", pch=15, cex=3)
```

##Hierarchical clustering in R

The 'hclust()' function is the main Hierarchical clustering method in R and it **must** be passed a *distance matrix* as input, not your raw data!

```{r}
hc <- hclust(dist(x))
hc
```

```{r}
plot(hc)
abline(h=3.5, col="red")
```

```{r}
table(cutree(hc, k=4))
```

```{r}
# Step 1. Generate some example data for clustering
x <- rbind(
 matrix(rnorm(100, mean=0, sd=0.3), ncol = 2), # c1
 matrix(rnorm(100, mean=1, sd=0.3), ncol = 2), # c2
 matrix(c(rnorm(50, mean=1, sd=0.3), # c3
 rnorm(50, mean=0, sd=0.3)), ncol = 2))
colnames(x) <- c("x", "y")
# Step 2. Plot the data without clustering
plot(x)
# Step 3. Generate colors for known clusters
# (just so we can compare to hclust results)
col <- as.factor( rep(c("c1","c2","c3"), each=50) )
plot(x, col=col)
```



Q. Use the dist(), hclust(), plot() and cutree()
 functions to return 2 and 3 clusters
 
```{r}
hc2 <- hclust(dist(x))
plot(hc2)
```
```{r}
grps3 <- cutree(hc2, k=3)
table(grps3)
```

Q. How does this compare to your known 'col' groups?





## 1. PCA of UK food data

The main function in base R for PCA is called `prcomp()`. Here we will use PCA to examine the funny food that folks eat in
the UK and N. Ireland.

```{r}
x <- read.csv("UK_foods.csv", row.names = 1)
x
```

Make more conventional plots
```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

```{r}
pairs(x, col=rainbow(10), pch=16)
```

#PCA to the rescue!
```{r}
pca <- prcomp(t(x))
```

```{r}
summary(pca)
pca
```

```{r}
attributes(pca)
```

```{r}
plot(pca$x[,1], pca$x[,2])
text(pca$x[,1], pca$x[,2], labels=colnames(x), col=c("black", "red", "blue", "dark blue"))
```

```{r}
plot(pca)
```

